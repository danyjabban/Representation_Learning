{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNetCIFAR\n",
    "from train_util import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "\n",
    "from FP_layers import *\n",
    "import os\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(device, 'torch.distributed.is_available():', torch.distributed.is_available())\n",
    "print(device)\n",
    "# torch.distributed.init_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lars.lars import LARS\n",
    "head = nn.Sequential(FP_Linear(64, 64, Nbits=None), nn.ReLU(True), FP_Linear(64, 64, Nbits=None))\n",
    "\n",
    "# model = nn.parallel.DistributedDataParallel(ResNetCIFAR(head_g=head))\n",
    "# model = nn.DataParallel(ResNetCIFAR(head_g=head))\n",
    "\n",
    "batch_size = int(256)\n",
    "# world_size = torch.cuda.device_count()\n",
    "# print(world_size)\n",
    "# mp.spawn(train, args=(world_size, 100, batch_size, 0.3*batch_size/256, 1e-6, head, 50,), nprocs=world_size, join='True')\n",
    "\n",
    "\n",
    "# rank, world_size, epochs, batch_size, lr, reg, head, log_every_n=50):\n",
    "# train(model, epochs=100, batch_size=batch_size, lr=0.3*batch_size/256, reg=1e-6, world_size=world_size, log_every_n=50)\n",
    "# net, epochs, batch_size, lr, reg, rank, world_size, log_every_n=50\n",
    "# optimizer = LARS(model.parameters(), lr=0.1, momentum=0.9)\n",
    "# optimizer.zero_grad()\n",
    "# loss_fn(model(input), target).backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.parallel.DistributedDataParallel(ResNetCIFAR(head_g=head))\n",
    "model = nn.DataParallel(ResNetCIFAR(head_g=head)).to(device)\n",
    "\n",
    "train_no_DDP(model, epochs=1000, batch_size=batch_size, lr=0.3*batch_size/256, reg=1e-6, log_every_n=20)\n",
    "\n",
    "# # b = torch.rand((64, 3, 28, 28))\n",
    "# head = nn.Sequential(FP_Linear(64, 64, Nbits=None), nn.ReLU(True), FP_Linear(64, 64, Nbits=None))\n",
    "\n",
    "# model = ResNetCIFAR(head_g=head).to(device)\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transforms.ToTensor())\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=1)\n",
    "# b = None\n",
    "# for idx, (inputs, label) in enumerate(trainloader):\n",
    "#     print(inputs.shape)\n",
    "#     b = inputs.to(device)\n",
    "#     break\n",
    "\n",
    "# y = model(b)\n",
    "\n",
    "# # xcs = F.cosine_similarity(y[None, :, :], y[:,None,:], dim=-1)\n",
    "# # ce_loss = F.cross_entropy(xcs / temperature, target, reduction=\"mean\")\n",
    "# # diff_sum = 0\n",
    "# # for rr, cc in enumerate(range(128)):\n",
    "#     # diff_sum += xcs[rr, cc] - F.cosine_similarity(y[rr, :], y[cc, :], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "michael_pytorch",
   "language": "python",
   "name": "michael_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
