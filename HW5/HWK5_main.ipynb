{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Adversarial Attacks and Defenses\n",
    "\n",
    "Duke University\n",
    "\n",
    "ECE661 Fall 2022\n",
    "\n",
    "## Setup\n",
    "\n",
    "You shouldn't have to change anything in these cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Custom\n",
    "import models\n",
    "import attacks\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('./data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size = 64, shuffle=True, )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST('./data', train=False, download=True, transform=transforms.ToTensor()),\n",
    "    batch_size = 64, shuffle=False, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(mdl, loader, device):\n",
    "    mdl.eval()\n",
    "    running_correct = 0.\n",
    "    running_loss = 0.\n",
    "    running_total = 0.\n",
    "    with torch.no_grad():\n",
    "        for batch_idx,(data,labels) in enumerate(loader):\n",
    "            data = data.to(device); labels = labels.to(device)\n",
    "            clean_outputs = mdl(data)\n",
    "            clean_loss = F.cross_entropy(clean_outputs, labels)\n",
    "            _,clean_preds = clean_outputs.max(1)\n",
    "            running_correct += clean_preds.eq(labels).sum().item()\n",
    "            running_loss += clean_loss.item()\n",
    "            running_total += labels.size(0)\n",
    "    clean_acc = running_correct/running_total\n",
    "    clean_loss = running_loss/len(loader)\n",
    "    mdl.train()\n",
    "    return clean_acc,clean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Train a model and save the checkpoint. This cell is used in Lab-1 and Lab-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick a model architecture\n",
    "which_net = 'B'\n",
    "test_acc_arr_lab2a = []\n",
    "\n",
    "if which_net == 'A':\n",
    "    net = models.NetA().to(device)\n",
    "    ## Checkpoint name for this model\n",
    "    model_checkpoint = \"netA_standard.pt\"\n",
    "if which_net == 'B':\n",
    "    net = models.NetB().to(device)\n",
    "    model_checkpoint = \"netB_standard.pt\"\n",
    "\n",
    "## Basic training params\n",
    "num_epochs = 20\n",
    "initial_lr = 0.001\n",
    "lr_decay_epoch = 15\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=initial_lr)\n",
    "\n",
    "## Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    train_correct = 0.\n",
    "    train_loss = 0.\n",
    "    train_total = 0.\n",
    "    for batch_idx,(data,labels) in enumerate(train_loader):\n",
    "        data = data.to(device); labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = net(data)\n",
    "        net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        # Compute loss, gradients, and update params\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update stats\n",
    "        _,preds = outputs.max(1)\n",
    "        train_correct += preds.eq(labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "        train_total += labels.size(0)\n",
    "        \n",
    "    # End of training epoch\n",
    "    test_acc,test_loss = test_model(net,test_loader,device)\n",
    "    test_acc_arr_lab2a.append(test_acc)\n",
    "    print(\"Epoch: [ {} / {} ]; TrainAcc: {:.5f}; TrainLoss: {:.5f}; TestAcc: {:.5f}; TestLoss: {:.5f}\".format(\n",
    "        epoch, num_epochs, train_correct/train_total, train_loss/len(train_loader),\n",
    "        test_acc, test_loss,\n",
    "    ))\n",
    "    # Save model    \n",
    "    torch.save(net.state_dict(), model_checkpoint)\n",
    "    \n",
    "    # Update LR\n",
    "    if epoch == lr_decay_epoch:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = initial_lr*0.1\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "xx = range(num_epochs)\n",
    "ax.plot(xx, test_acc_arr_lab2a, label='final test accuracy: %g' % (test_acc_arr_lab2a[-1]))\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('lab1a net%s Accuracy vs Epochs' % which_net)\n",
    "ax.legend()\n",
    "\n",
    "# plt.savefig('Figures/lab1a_net%s.pdf' % which_net, dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize some perturbed samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"t-shirt\", \"trouser\",\"pullover\",\"dress\",\"coat\",\"sandal\",\"shirt\",\"sneaker\",\"bag\",\"boot\"]\n",
    "net = models.NetA().to(device)\n",
    "net.load_state_dict(torch.load(\"netA_standard.pt\"))\n",
    "lab1_part = 'c2'  # possible values: 'b', 'c1', 'c2', 'd'; change this to plot lab1 b/c/d\n",
    "lab1_save_name = {'b': 'PGD_attack', 'c1': 'FGSM_attack', 'c2': 'rFGSM_attack', 'd': 'FGM_L2_attack'}\n",
    "EPS_list_lab1 = np.array([0, 0.005, 0.02, 0.05, 0.075, 0.1, 0.15, 0.2])\n",
    "if lab1_part == 'd':\n",
    "    EPS_list_lab1 = np.array([0, 0.3, 1, 1.5, 2, 3, 3.5, 4])\n",
    "print('EPS_list_lab1', EPS_list_lab1)\n",
    "for epsilon in EPS_list_lab1:\n",
    "    for data, labels in test_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        ###\n",
    "        # Compute and apply adversarial perturbation to data\n",
    "        # EPS in [0.0, 0.2]\n",
    "        EPS = epsilon\n",
    "        if lab1_part == 'b' or lab1_part == 'c1' or lab1_part == 'c2':\n",
    "            assert EPS <= 0.2 and EPS >= 0.0 \n",
    "        elif lab1_part == 'd':\n",
    "            assert EPS <= 4 and EPS >= 0.0 \n",
    "        else:\n",
    "            raise KeyError(\"check lab1_part param\")\n",
    "        ITS = 10\n",
    "        ALP = 1.85 * (EPS/ITS)\n",
    "        if lab1_part == 'b':\n",
    "            adv_data, _ = attacks.PGD_attack(model=net, device=device, dat=data, lbl=labels, eps=EPS, alpha=ALP, iters=ITS, rand_start=True)\n",
    "        if lab1_part == 'c1':\n",
    "            adv_data, _ = attacks.FGSM_attack(model=net, device=device, dat=data, lbl=labels, eps=EPS)\n",
    "        if lab1_part == 'c2':\n",
    "            adv_data, _ = attacks.rFGSM_attack(model=net, device=device, dat=data, lbl=labels, eps=EPS)\n",
    "        if lab1_part == 'd':\n",
    "            adv_data, _ = attacks.FGM_L2_attack(model=net, device=device, dat=data, lbl=labels, eps=EPS)\n",
    "        ###\n",
    "        \n",
    "        # Compute preds\n",
    "        with torch.no_grad():\n",
    "            clean_outputs = net(data)\n",
    "            _,clean_preds = clean_outputs.max(1)\n",
    "            clean_preds = clean_preds.cpu().squeeze().numpy()\n",
    "            adv_outputs = net(adv_data)\n",
    "            _,adv_preds = adv_outputs.max(1)\n",
    "            adv_preds = adv_preds.cpu().squeeze().numpy()\n",
    "\n",
    "        # Plot some samples\n",
    "        inds = random.sample(list(range(data.size(0))),6)\n",
    "        plt.figure(figsize=(15,5))\n",
    "        for jj in range(6):\n",
    "            plt.subplot(2, 6, jj+1)\n",
    "            plt.imshow(data[inds[jj],0].cpu().numpy(),cmap='gray')\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"clean. pred={}\".format(classes[clean_preds[inds[jj]]]))\n",
    "        for jj in range(6):\n",
    "            plt.subplot(2, 6, 6+jj+1)\n",
    "            plt.imshow(adv_data[inds[jj],0].cpu().numpy(),cmap='gray')\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"adv. pred={}\".format(classes[adv_preds[inds[jj]]]))\n",
    "        plt.suptitle(\"eps=%g\" % EPS)\n",
    "        plt.tight_layout()\n",
    "        # plt.show()\n",
    "        plt.savefig('Figures/lab1%s_netA_eps_%g_%s.pdf' % (lab1_part, EPS, lab1_save_name[lab1_part]), dpi=500, bbox_inches='tight')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Attacks - Whitebox & Blackbox\n",
    "\n",
    "Don't forget to plot accuracy vs. epsilon curves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lab2_white_black(epsilon_arr, white_acc_d, black_acc_d, label_names):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    for label_name in label_names:\n",
    "        ax[0].plot(epsilon_arr, white_acc_d[label_name], label=label_name)\n",
    "        ax[0].set_xlabel('eps')\n",
    "        ax[0].set_ylabel('Accuracy')\n",
    "        ax[0].set_title('Whitebox Attack')\n",
    "\n",
    "        ax[1].plot(epsilon_arr, black_acc_d[label_name], label=label_name)\n",
    "        ax[1].set_xlabel('eps')\n",
    "        ax[1].set_ylabel('Accuracy')\n",
    "        ax[1].set_title('Blackbox Attack')\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('Figures/lab2bcd_attacks.pdf', dpi=500, bbox_inches='tight')\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def lab2_bcd_return_adv_data(model, device, dat, lbl, eps, alpha, iters, rand_start, question_label):\n",
    "    if question_label == 'Random':\n",
    "        return attacks.random_noise_attack(model=None, device=device, dat=dat, eps=eps)[0]\n",
    "    elif question_label == 'FGSM':\n",
    "        return attacks.FGSM_attack(model, device, dat, lbl, eps)[0]\n",
    "    elif question_label == 'rFGSM':\n",
    "        return attacks.rFGSM_attack(model, device, dat, lbl, eps)[0]\n",
    "    elif question_label == 'PGD':\n",
    "        return attacks.PGD_attack(model, device, dat, lbl, eps, alpha, iters, rand_start)[0]\n",
    "    else:\n",
    "        raise KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS_list_lab2 = np.linspace(0, 0.1, 11)\n",
    "print('EPS_list_lab2', EPS_list_lab2)\n",
    "lab2_label = ['Random', 'FGSM', 'rFGSM', 'PGD']\n",
    "# lab2_label = {'FGSM'}\n",
    "white_acc_dict, black_acc_dict = {'Random': [], 'FGSM': [], 'rFGSM': [], 'PGD': []}, {'Random': [], 'FGSM': [], 'rFGSM': [], 'PGD': []}\n",
    "\n",
    "for epsilon in EPS_list_lab2:\n",
    "    print('epsilon', epsilon)\n",
    "    for q_label in lab2_label:\n",
    "        print('q_label', q_label)\n",
    "        white_acc_lst, black_acc_lst = [], []\n",
    "        ## Load pretrained models\n",
    "        whitebox = models.NetA()\n",
    "        blackbox = models.NetB()\n",
    "\n",
    "        whitebox.load_state_dict(torch.load(\"netA_standard.pt\")) # TODO\n",
    "        blackbox.load_state_dict(torch.load(\"netB_standard.pt\")) # TODO\n",
    "\n",
    "        whitebox, blackbox = whitebox.to(device), blackbox.to(device) \n",
    "        whitebox.eval()\n",
    "        blackbox.eval()\n",
    "\n",
    "        test_acc,_ = test_model(whitebox, test_loader, device)\n",
    "        print(\"Initial Accuracy of Whitebox Model: \",test_acc)\n",
    "        test_acc,_ = test_model(blackbox, test_loader, device)\n",
    "        print(\"Initial Accuracy of Blackbox Model: \", test_acc)\n",
    "\n",
    "        ## Test the models against an adversarial attack\n",
    "\n",
    "        # TODO: Set attack parameters here\n",
    "        ATK_EPS = epsilon\n",
    "        ATK_ITERS = 10\n",
    "        ATK_ALPHA = 1.85 * (ATK_EPS/ATK_ITERS)\n",
    "\n",
    "        whitebox_correct = 0.\n",
    "        blackbox_correct = 0.\n",
    "        running_total = 0.\n",
    "        for batch_idx, (data, labels) in enumerate(test_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            # TODO: Perform adversarial attack here\n",
    "            adv_data = lab2_bcd_return_adv_data(model=whitebox, device=device, dat=data, lbl=labels, eps=ATK_EPS, \n",
    "                                                alpha=ATK_ALPHA, iters=ATK_ITERS, rand_start=True, question_label=q_label)\n",
    "            # Sanity checking if adversarial example is \"legal\"\n",
    "            assert(torch.max(torch.abs(adv_data-data)) <= (ATK_EPS + 1e-5)), \\\n",
    "                \"torch.max(torch.abs(adv_data-data)) = %g, %s, ATK_EPS=%g\" % (torch.max(torch.abs(adv_data-data)), q_label, ATK_EPS)\n",
    "            assert(adv_data.max() == 1.), \"adv_data.max() = %g, %s, ATK_EPS=%g\" % (adv_data.max(), q_label, ATK_EPS)\n",
    "            assert(adv_data.min() == 0.), \"adv_data.min() = %g, %s, ATK_EPS=%g\" % (adv_data.min(), q_label, ATK_EPS)\n",
    "            \n",
    "            # Compute accuracy on perturbed data\n",
    "            with torch.no_grad():\n",
    "                # Stat keeping - whitebox\n",
    "                whitebox_outputs = whitebox(adv_data)\n",
    "                _,whitebox_preds = whitebox_outputs.max(1)\n",
    "                whitebox_correct += whitebox_preds.eq(labels).sum().item()\n",
    "                # Stat keeping - blackbox\n",
    "                blackbox_outputs = blackbox(adv_data)\n",
    "                _,blackbox_preds = blackbox_outputs.max(1)\n",
    "                blackbox_correct += blackbox_preds.eq(labels).sum().item()\n",
    "                running_total += labels.size(0)\n",
    "            \n",
    "            # # Plot some samples\n",
    "            # if batch_idx == 1:\n",
    "            #     plt.figure(figsize=(15,5))\n",
    "            #     for jj in range(12):\n",
    "            #         plt.subplot(2,6,jj+1);plt.imshow(adv_data[jj,0].cpu().numpy(),cmap='gray');plt.axis(\"off\")\n",
    "            #     plt.tight_layout()\n",
    "            #     plt.show()\n",
    "\n",
    "        # Print final \n",
    "        whitebox_acc = whitebox_correct/running_total\n",
    "        blackbox_acc = blackbox_correct/running_total\n",
    "\n",
    "        white_acc_dict[q_label].append(whitebox_acc)\n",
    "        black_acc_dict[q_label].append(blackbox_acc)\n",
    "        print(\"Attack Epsilon: {}; Whitebox Accuracy: {}; Blackbox Accuracy: {}\".format(ATK_EPS, whitebox_acc, blackbox_acc))\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plot_lab2_white_black(epsilon_arr=EPS_list_lab2, white_acc_d=white_acc_dict, black_acc_d=black_acc_dict, \n",
    "                             label_names=lab2_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Robust Models\n",
    "\n",
    "Don't forget to plot accuracy vs. epsilon curves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitebox = models.NetA()\n",
    "whitebox.load_state_dict(torch.load()) # TODO: Load your robust models\n",
    "whitebox = whitebox.to(device)\n",
    "whitebox.eval(); \n",
    "\n",
    "test_acc,_ = test_model(whitebox,test_loader,device)\n",
    "print(\"Initial Accuracy of Whitebox Model: \",test_acc)\n",
    "\n",
    "## Test the model against an adversarial attack\n",
    "\n",
    "# TODO: Set attack parameters here\n",
    "#ATK_EPS = ?\n",
    "#ATK_ITERS = ?\n",
    "#ATK_ALPHA = ?\n",
    "\n",
    "whitebox_correct = 0.\n",
    "running_total = 0.\n",
    "for batch_idx,(data,labels) in enumerate(test_loader):\n",
    "    data = data.to(device) \n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # TODO: Perform adversarial attack here\n",
    "    \n",
    "    # Sanity checking if adversarial example is \"legal\"\n",
    "    assert(torch.max(torch.abs(adv_data-data)) <= (ATK_EPS + 1e-5) )\n",
    "    assert(adv_data.max() == 1.)\n",
    "    assert(adv_data.min() == 0.)\n",
    "    \n",
    "    # Compute accuracy on perturbed data\n",
    "    with torch.no_grad():\n",
    "        whitebox_outputs = whitebox(adv_data)\n",
    "        _,whitebox_preds = whitebox_outputs.max(1)\n",
    "        whitebox_correct += whitebox_preds.eq(labels).sum().item()\n",
    "        running_total += labels.size(0)\n",
    "    \n",
    "    # Plot some samples\n",
    "    if batch_idx == 1:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        for jj in range(12):\n",
    "            plt.subplot(2,6,jj+1);plt.imshow(adv_data[jj,0].cpu().numpy(),cmap='gray');plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Print final \n",
    "whitebox_acc = whitebox_correct/running_total\n",
    "print(\"Attack Epsilon: {}; Whitebox Accuracy: {}\".format(ATK_EPS, whitebox_acc))\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "michael_pytorch",
   "language": "python",
   "name": "michael_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
