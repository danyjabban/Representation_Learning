hparam 0
EMBEDDING_DIM=32,HIDDEN_DIM=20,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 1,819,690 trainable parameters
Saving ...
epoch: 1
train_loss: 0.549, train_acc: 0.726
valid_loss: 0.335, valid_acc: 0.858
Saving ...
epoch: 2
train_loss: 0.216, train_acc: 0.916
valid_loss: 0.278, valid_acc: 0.890
Saving ...
epoch: 3
train_loss: 0.071, train_acc: 0.977
valid_loss: 0.372, valid_acc: 0.875
Saving ...
epoch: 4
train_loss: 0.022, train_acc: 0.994
valid_loss: 0.482, valid_acc: 0.880
Saving ...
epoch: 5
train_loss: 0.008, train_acc: 0.998
valid_loss: 0.559, valid_acc: 0.874
test_loss: 0.579, test_acc: 0.872


hparam 1
EMBEDDING_DIM=188,HIDDEN_DIM=20,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 10,681,894 trainable parameters
Saving ...
epoch: 1
train_loss: 0.549, train_acc: 0.724
valid_loss: 0.383, valid_acc: 0.839
Saving ...
epoch: 2
train_loss: 0.236, train_acc: 0.910
valid_loss: 0.329, valid_acc: 0.874
Saving ...
epoch: 3
train_loss: 0.088, train_acc: 0.969
valid_loss: 0.356, valid_acc: 0.874
Saving ...
epoch: 4
train_loss: 0.033, train_acc: 0.989
valid_loss: 0.517, valid_acc: 0.866
Saving ...
epoch: 5
train_loss: 0.016, train_acc: 0.995
valid_loss: 0.589, valid_acc: 0.873
test_loss: 0.632, test_acc: 0.863


hparam 2
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=20,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 14,544,906 trainable parameters
Saving ...
epoch: 1
train_loss: 0.552, train_acc: 0.726
valid_loss: 0.363, valid_acc: 0.858
Saving ...
epoch: 2
train_loss: 0.270, train_acc: 0.901
valid_loss: 0.316, valid_acc: 0.869
Saving ...
epoch: 3
train_loss: 0.142, train_acc: 0.953
valid_loss: 0.361, valid_acc: 0.868
Saving ...
epoch: 4
train_loss: 0.076, train_acc: 0.975
valid_loss: 0.446, valid_acc: 0.863
Saving ...
epoch: 5
train_loss: 0.042, train_acc: 0.987
valid_loss: 0.546, valid_acc: 0.864
test_loss: 0.570, test_acc: 0.858


hparam 3
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=280,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 2,167,570 trainable parameters
Saving ...
epoch: 1
train_loss: 0.721, train_acc: 0.542
valid_loss: 0.677, valid_acc: 0.568
Saving ...
epoch: 2
train_loss: 0.643, train_acc: 0.629
valid_loss: 0.677, valid_acc: 0.594
Saving ...
epoch: 3
train_loss: 0.582, train_acc: 0.688
valid_loss: 0.696, valid_acc: 0.604
Saving ...
epoch: 4
train_loss: 0.541, train_acc: 0.719
valid_loss: 0.676, valid_acc: 0.619
Saving ...
epoch: 5
train_loss: 0.490, train_acc: 0.756
valid_loss: 0.707, valid_acc: 0.638
test_loss: 0.692, test_acc: 0.636


hparam 4
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=280,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 11,192,014 trainable parameters
Saving ...
epoch: 1
train_loss: 0.488, train_acc: 0.761
valid_loss: 0.308, valid_acc: 0.870
Saving ...
epoch: 2
train_loss: 0.232, train_acc: 0.909
valid_loss: 0.294, valid_acc: 0.885
Saving ...
epoch: 3
train_loss: 0.108, train_acc: 0.964
valid_loss: 0.337, valid_acc: 0.881
Saving ...
epoch: 4
train_loss: 0.055, train_acc: 0.982
valid_loss: 0.481, valid_acc: 0.876
Saving ...
epoch: 5
train_loss: 0.032, train_acc: 0.989
valid_loss: 0.603, valid_acc: 0.866
test_loss: 0.652, test_acc: 0.858


hparam 5
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=280,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 15,125,746 trainable parameters
Saving ...
epoch: 1
train_loss: 0.510, train_acc: 0.752
valid_loss: 0.312, valid_acc: 0.876
Saving ...
epoch: 2
train_loss: 0.210, train_acc: 0.921
valid_loss: 0.295, valid_acc: 0.882
Saving ...
epoch: 3
train_loss: 0.110, train_acc: 0.961
valid_loss: 0.425, valid_acc: 0.873
Saving ...
epoch: 4
train_loss: 0.067, train_acc: 0.976
valid_loss: 0.412, valid_acc: 0.867
Saving ...
epoch: 5
train_loss: 0.037, train_acc: 0.988
valid_loss: 0.600, valid_acc: 0.868
test_loss: 0.617, test_acc: 0.863


hparam 6
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=290,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 2,191,750 trainable parameters
Saving ...
epoch: 1
train_loss: 0.709, train_acc: 0.579
valid_loss: 0.694, valid_acc: 0.574
Saving ...
epoch: 2
train_loss: 0.468, train_acc: 0.782
valid_loss: 0.411, valid_acc: 0.816
Saving ...
epoch: 3
train_loss: 0.310, train_acc: 0.873
valid_loss: 0.353, valid_acc: 0.851
Saving ...
epoch: 4
train_loss: 0.198, train_acc: 0.926
valid_loss: 0.343, valid_acc: 0.870
Saving ...
epoch: 5
train_loss: 0.139, train_acc: 0.951
valid_loss: 0.355, valid_acc: 0.864
test_loss: 0.364, test_acc: 0.859


hparam 7
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=290,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 11,222,434 trainable parameters
Saving ...
epoch: 1
train_loss: 0.507, train_acc: 0.755
valid_loss: 0.378, valid_acc: 0.844
Saving ...
epoch: 2
train_loss: 0.233, train_acc: 0.909
valid_loss: 0.312, valid_acc: 0.868
Saving ...
epoch: 3
train_loss: 0.111, train_acc: 0.962
valid_loss: 0.351, valid_acc: 0.873
Saving ...
epoch: 4
train_loss: 0.057, train_acc: 0.981
valid_loss: 0.481, valid_acc: 0.873
Saving ...
epoch: 5
train_loss: 0.034, train_acc: 0.988
valid_loss: 0.639, valid_acc: 0.875
test_loss: 0.666, test_acc: 0.869


hparam 8
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=290,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 15,158,886 trainable parameters
Saving ...
epoch: 1
train_loss: 0.504, train_acc: 0.752
valid_loss: 0.313, valid_acc: 0.869
Saving ...
epoch: 2
train_loss: 0.217, train_acc: 0.917
valid_loss: 0.318, valid_acc: 0.884
Saving ...
epoch: 3
train_loss: 0.115, train_acc: 0.959
valid_loss: 0.361, valid_acc: 0.869
Saving ...
epoch: 4
train_loss: 0.065, train_acc: 0.978
valid_loss: 0.410, valid_acc: 0.862
Saving ...
epoch: 5
train_loss: 0.043, train_acc: 0.985
valid_loss: 0.574, valid_acc: 0.863
test_loss: 0.600, test_acc: 0.865


hparam 9
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=305,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 2,229,520 trainable parameters
Saving ...
epoch: 1
train_loss: 0.533, train_acc: 0.736
valid_loss: 0.575, valid_acc: 0.677
Saving ...
epoch: 2
train_loss: 0.251, train_acc: 0.900
valid_loss: 0.332, valid_acc: 0.873
Saving ...
epoch: 3
train_loss: 0.128, train_acc: 0.954
valid_loss: 0.333, valid_acc: 0.881
Saving ...
epoch: 4
train_loss: 0.057, train_acc: 0.982
valid_loss: 0.434, valid_acc: 0.875
Saving ...
epoch: 5
train_loss: 0.027, train_acc: 0.992
valid_loss: 0.678, valid_acc: 0.866
test_loss: 0.701, test_acc: 0.861


hparam 10
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=305,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 11,269,564 trainable parameters
Saving ...
epoch: 1
train_loss: 0.542, train_acc: 0.758
valid_loss: 0.323, valid_acc: 0.863
Saving ...
epoch: 2
train_loss: 0.217, train_acc: 0.917
valid_loss: 0.300, valid_acc: 0.878
Saving ...
epoch: 3
train_loss: 0.101, train_acc: 0.965
valid_loss: 0.374, valid_acc: 0.877
Saving ...
epoch: 4
train_loss: 0.049, train_acc: 0.984
valid_loss: 0.444, valid_acc: 0.874
Saving ...
epoch: 5
train_loss: 0.029, train_acc: 0.991
valid_loss: 0.576, valid_acc: 0.876
test_loss: 0.610, test_acc: 0.875


hparam 11
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=305,LR=0.001,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 15,210,096 trainable parameters
Saving ...
epoch: 1
train_loss: 0.509, train_acc: 0.757
valid_loss: 0.323, valid_acc: 0.867
Saving ...
epoch: 2
train_loss: 0.211, train_acc: 0.919
valid_loss: 0.328, valid_acc: 0.884
Saving ...
epoch: 3
train_loss: 0.103, train_acc: 0.964
valid_loss: 0.393, valid_acc: 0.877
Saving ...
epoch: 4
train_loss: 0.057, train_acc: 0.981
valid_loss: 0.464, valid_acc: 0.870
Saving ...
epoch: 5
train_loss: 0.037, train_acc: 0.988
valid_loss: 0.581, valid_acc: 0.870
test_loss: 0.596, test_acc: 0.861


hparam 12
EMBEDDING_DIM=32,HIDDEN_DIM=20,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 1,823,050 trainable parameters
Saving ...
epoch: 1
train_loss: 0.499, train_acc: 0.758
valid_loss: 0.406, valid_acc: 0.827
Saving ...
epoch: 2
train_loss: 0.310, train_acc: 0.873
valid_loss: 0.340, valid_acc: 0.856
Saving ...
epoch: 3
train_loss: 0.179, train_acc: 0.934
valid_loss: 0.331, valid_acc: 0.869
Saving ...
epoch: 4
train_loss: 0.090, train_acc: 0.968
valid_loss: 0.332, valid_acc: 0.878
Saving ...
epoch: 5
train_loss: 0.039, train_acc: 0.988
valid_loss: 0.463, valid_acc: 0.873
test_loss: 0.492, test_acc: 0.869


hparam 13
EMBEDDING_DIM=188,HIDDEN_DIM=20,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 10,685,254 trainable parameters
Saving ...
epoch: 1
train_loss: 0.475, train_acc: 0.778
valid_loss: 0.341, valid_acc: 0.863
Saving ...
epoch: 2
train_loss: 0.241, train_acc: 0.908
valid_loss: 0.332, valid_acc: 0.870
Saving ...
epoch: 3
train_loss: 0.138, train_acc: 0.952
valid_loss: 0.385, valid_acc: 0.861
Saving ...
epoch: 4
train_loss: 0.074, train_acc: 0.975
valid_loss: 0.398, valid_acc: 0.869
Saving ...
epoch: 5
train_loss: 0.039, train_acc: 0.986
valid_loss: 0.507, valid_acc: 0.858
test_loss: 0.558, test_acc: 0.853


hparam 14
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=20,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 14,548,266 trainable parameters
Saving ...
epoch: 1
train_loss: 0.547, train_acc: 0.719
valid_loss: 0.329, valid_acc: 0.866
Saving ...
epoch: 2
train_loss: 0.229, train_acc: 0.913
valid_loss: 0.270, valid_acc: 0.889
Saving ...
epoch: 3
train_loss: 0.086, train_acc: 0.972
valid_loss: 0.391, valid_acc: 0.872
Saving ...
epoch: 4
train_loss: 0.036, train_acc: 0.989
valid_loss: 0.409, valid_acc: 0.872
Saving ...
epoch: 5
train_loss: 0.020, train_acc: 0.994
valid_loss: 0.589, valid_acc: 0.864
test_loss: 0.586, test_acc: 0.867


hparam 15
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=280,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 2,797,010 trainable parameters
Saving ...
epoch: 1
train_loss: 0.523, train_acc: 0.733
valid_loss: 0.490, valid_acc: 0.815
Saving ...
epoch: 2
train_loss: 0.270, train_acc: 0.895
valid_loss: 0.334, valid_acc: 0.864
Saving ...
epoch: 3
train_loss: 0.179, train_acc: 0.933
valid_loss: 0.322, valid_acc: 0.871
Saving ...
epoch: 4
train_loss: 0.125, train_acc: 0.957
valid_loss: 0.348, valid_acc: 0.871
Saving ...
epoch: 5
train_loss: 0.083, train_acc: 0.973
valid_loss: 0.382, valid_acc: 0.876
test_loss: 0.390, test_acc: 0.872


hparam 16
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=280,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 11,821,454 trainable parameters
Saving ...
epoch: 1
train_loss: 0.494, train_acc: 0.758
valid_loss: 0.308, valid_acc: 0.876
Saving ...
epoch: 2
train_loss: 0.231, train_acc: 0.912
valid_loss: 0.303, valid_acc: 0.872
Saving ...
epoch: 3
train_loss: 0.131, train_acc: 0.955
valid_loss: 0.358, valid_acc: 0.881
Saving ...
epoch: 4
train_loss: 0.074, train_acc: 0.977
valid_loss: 0.417, valid_acc: 0.879
Saving ...
epoch: 5
train_loss: 0.044, train_acc: 0.985
valid_loss: 0.570, valid_acc: 0.873
test_loss: 0.621, test_acc: 0.870


hparam 17
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=280,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 15,755,186 trainable parameters
Saving ...
epoch: 1
train_loss: 0.491, train_acc: 0.756
valid_loss: 0.309, valid_acc: 0.866
Saving ...
epoch: 2
train_loss: 0.239, train_acc: 0.908
valid_loss: 0.309, valid_acc: 0.881
Saving ...
epoch: 3
train_loss: 0.155, train_acc: 0.944
valid_loss: 0.306, valid_acc: 0.874
Saving ...
epoch: 4
train_loss: 0.100, train_acc: 0.967
valid_loss: 0.365, valid_acc: 0.886
Saving ...
epoch: 5
train_loss: 0.070, train_acc: 0.978
valid_loss: 0.441, valid_acc: 0.878
test_loss: 0.449, test_acc: 0.873


hparam 18
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=290,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 2,866,870 trainable parameters
Saving ...
epoch: 1
train_loss: 0.667, train_acc: 0.577
valid_loss: 0.495, valid_acc: 0.761
Saving ...
epoch: 2
train_loss: 0.347, train_acc: 0.855
valid_loss: 0.298, valid_acc: 0.876
Saving ...
epoch: 3
train_loss: 0.187, train_acc: 0.932
valid_loss: 0.357, valid_acc: 0.880
Saving ...
epoch: 4
train_loss: 0.111, train_acc: 0.963
valid_loss: 0.317, valid_acc: 0.887
Saving ...
epoch: 5
train_loss: 0.066, train_acc: 0.978
valid_loss: 0.445, valid_acc: 0.874
test_loss: 0.442, test_acc: 0.871


hparam 19
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=290,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 11,897,554 trainable parameters
Saving ...
epoch: 1
train_loss: 0.605, train_acc: 0.677
valid_loss: 0.399, valid_acc: 0.826
Saving ...
epoch: 2
train_loss: 0.319, train_acc: 0.868
valid_loss: 0.326, valid_acc: 0.861
Saving ...
epoch: 3
train_loss: 0.217, train_acc: 0.918
valid_loss: 0.319, valid_acc: 0.860
Saving ...
epoch: 4
train_loss: 0.146, train_acc: 0.949
valid_loss: 0.399, valid_acc: 0.855
Saving ...
epoch: 5
train_loss: 0.102, train_acc: 0.965
valid_loss: 0.415, valid_acc: 0.859
test_loss: 0.421, test_acc: 0.860


hparam 20
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=290,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 15,834,006 trainable parameters
Saving ...
epoch: 1
train_loss: 0.526, train_acc: 0.739
valid_loss: 0.385, valid_acc: 0.830
Saving ...
epoch: 2
train_loss: 0.256, train_acc: 0.899
valid_loss: 0.306, valid_acc: 0.874
Saving ...
epoch: 3
train_loss: 0.156, train_acc: 0.944
valid_loss: 0.342, valid_acc: 0.880
Saving ...
epoch: 4
train_loss: 0.102, train_acc: 0.966
valid_loss: 0.348, valid_acc: 0.878
Saving ...
epoch: 5
train_loss: 0.061, train_acc: 0.981
valid_loss: 0.430, valid_acc: 0.876
test_loss: 0.455, test_acc: 0.872


hparam 21
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=305,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 2,976,160 trainable parameters
Saving ...
epoch: 1
train_loss: 0.639, train_acc: 0.646
valid_loss: 0.598, valid_acc: 0.682
Saving ...
epoch: 2
train_loss: 0.344, train_acc: 0.854
valid_loss: 0.306, valid_acc: 0.870
Saving ...
epoch: 3
train_loss: 0.194, train_acc: 0.929
valid_loss: 0.368, valid_acc: 0.856
Saving ...
epoch: 4
train_loss: 0.117, train_acc: 0.960
valid_loss: 0.320, valid_acc: 0.875
Saving ...
epoch: 5
train_loss: 0.055, train_acc: 0.983
valid_loss: 0.419, valid_acc: 0.882
test_loss: 0.441, test_acc: 0.880


hparam 22
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=305,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 12,016,204 trainable parameters
Saving ...
epoch: 1
train_loss: 0.530, train_acc: 0.728
valid_loss: 0.308, valid_acc: 0.870
Saving ...
epoch: 2
train_loss: 0.239, train_acc: 0.908
valid_loss: 0.301, valid_acc: 0.882
Saving ...
epoch: 3
train_loss: 0.132, train_acc: 0.952
valid_loss: 0.330, valid_acc: 0.878
Saving ...
epoch: 4
train_loss: 0.073, train_acc: 0.977
valid_loss: 0.437, valid_acc: 0.878
Saving ...
epoch: 5
train_loss: 0.048, train_acc: 0.985
valid_loss: 0.548, valid_acc: 0.857
test_loss: 0.573, test_acc: 0.849


hparam 23
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=305,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 15,956,736 trainable parameters
Saving ...
epoch: 1
train_loss: 0.721, train_acc: 0.514
valid_loss: 0.673, valid_acc: 0.606
Saving ...
epoch: 2
train_loss: 0.474, train_acc: 0.780
valid_loss: 0.387, valid_acc: 0.831
Saving ...
epoch: 3
train_loss: 0.278, train_acc: 0.890
valid_loss: 0.357, valid_acc: 0.858
Saving ...
epoch: 4
train_loss: 0.201, train_acc: 0.927
valid_loss: 0.355, valid_acc: 0.862
Saving ...
epoch: 5
train_loss: 0.144, train_acc: 0.949
valid_loss: 0.358, valid_acc: 0.877
test_loss: 0.389, test_acc: 0.865


hparam 24
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=20,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 1,826,410 trainable parameters
Saving ...
epoch: 1
train_loss: 0.658, train_acc: 0.599
valid_loss: 0.623, valid_acc: 0.669
Saving ...
epoch: 2
train_loss: 0.402, train_acc: 0.824
valid_loss: 0.301, valid_acc: 0.875
Saving ...
epoch: 3
train_loss: 0.198, train_acc: 0.928
valid_loss: 0.285, valid_acc: 0.886
Saving ...
epoch: 4
train_loss: 0.105, train_acc: 0.965
valid_loss: 0.298, valid_acc: 0.888
Saving ...
epoch: 5
train_loss: 0.054, train_acc: 0.983
valid_loss: 0.424, valid_acc: 0.874
test_loss: 0.448, test_acc: 0.869


hparam 25
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=20,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 10,688,614 trainable parameters
Saving ...
epoch: 1
train_loss: 0.581, train_acc: 0.698
valid_loss: 0.428, valid_acc: 0.810
Saving ...
epoch: 2
train_loss: 0.313, train_acc: 0.873
valid_loss: 0.322, valid_acc: 0.872
Saving ...
epoch: 3
train_loss: 0.178, train_acc: 0.935
valid_loss: 0.310, valid_acc: 0.879
Saving ...
epoch: 4
train_loss: 0.106, train_acc: 0.963
valid_loss: 0.371, valid_acc: 0.871
Saving ...
epoch: 5
train_loss: 0.060, train_acc: 0.981
valid_loss: 0.416, valid_acc: 0.873
test_loss: 0.447, test_acc: 0.862


hparam 26
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=20,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 14,551,626 trainable parameters
Saving ...
epoch: 1
train_loss: 0.543, train_acc: 0.724
valid_loss: 0.365, valid_acc: 0.841
Saving ...
epoch: 2
train_loss: 0.265, train_acc: 0.899
valid_loss: 0.302, valid_acc: 0.881
Saving ...
epoch: 3
train_loss: 0.130, train_acc: 0.955
valid_loss: 0.327, valid_acc: 0.874
Saving ...
epoch: 4
train_loss: 0.068, train_acc: 0.978
valid_loss: 0.423, valid_acc: 0.880
Saving ...
epoch: 5
train_loss: 0.032, train_acc: 0.990
valid_loss: 0.434, valid_acc: 0.871
test_loss: 0.437, test_acc: 0.866


hparam 27
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=280,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 3,426,450 trainable parameters
Saving ...
epoch: 1
train_loss: 0.699, train_acc: 0.494
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 2
train_loss: 0.694, train_acc: 0.497
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 3
train_loss: 0.693, train_acc: 0.498
valid_loss: 0.693, valid_acc: 0.499
Saving ...
epoch: 4
train_loss: 0.694, train_acc: 0.501
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 5
train_loss: 0.699, train_acc: 0.507
valid_loss: 0.691, valid_acc: 0.499
test_loss: 0.690, test_acc: 0.500


hparam 28
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=280,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 12,450,894 trainable parameters
Saving ...
epoch: 1
train_loss: 0.626, train_acc: 0.622
valid_loss: 0.378, valid_acc: 0.844
Saving ...
epoch: 2
train_loss: 0.325, train_acc: 0.868
valid_loss: 0.304, valid_acc: 0.878
Saving ...
epoch: 3
train_loss: 0.231, train_acc: 0.917
valid_loss: 0.366, valid_acc: 0.857
Saving ...
epoch: 4
train_loss: 0.152, train_acc: 0.949
valid_loss: 0.346, valid_acc: 0.867
Saving ...
epoch: 5
train_loss: 0.109, train_acc: 0.966
valid_loss: 0.371, valid_acc: 0.867
test_loss: 0.399, test_acc: 0.864


hparam 29
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=280,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 16,384,626 trainable parameters
Saving ...
epoch: 1
train_loss: 0.681, train_acc: 0.562
valid_loss: 0.666, valid_acc: 0.566
Saving ...
epoch: 2
train_loss: 0.403, train_acc: 0.824
valid_loss: 0.328, valid_acc: 0.867
Saving ...
epoch: 3
train_loss: 0.249, train_acc: 0.909
valid_loss: 0.463, valid_acc: 0.842
Saving ...
epoch: 4
train_loss: 0.184, train_acc: 0.937
valid_loss: 0.395, valid_acc: 0.865
Saving ...
epoch: 5
train_loss: 0.133, train_acc: 0.956
valid_loss: 0.350, valid_acc: 0.880
test_loss: 0.374, test_acc: 0.871


hparam 30
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=290,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 3,541,990 trainable parameters
Saving ...
epoch: 1
train_loss: 0.695, train_acc: 0.560
valid_loss: 0.684, valid_acc: 0.535
Saving ...
epoch: 2
train_loss: 0.371, train_acc: 0.841
valid_loss: 0.311, valid_acc: 0.861
Saving ...
epoch: 3
train_loss: 0.208, train_acc: 0.922
valid_loss: 0.298, valid_acc: 0.881
Saving ...
epoch: 4
train_loss: 0.141, train_acc: 0.952
valid_loss: 0.333, valid_acc: 0.882
Saving ...
epoch: 5
train_loss: 0.098, train_acc: 0.969
valid_loss: 0.341, valid_acc: 0.871
test_loss: 0.350, test_acc: 0.867


hparam 31
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=290,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 12,572,674 trainable parameters
Saving ...
epoch: 1
train_loss: 0.680, train_acc: 0.548
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 2
train_loss: 0.575, train_acc: 0.658
valid_loss: 0.417, valid_acc: 0.799
Saving ...
epoch: 3
train_loss: 0.299, train_acc: 0.883
valid_loss: 0.323, valid_acc: 0.870
Saving ...
epoch: 4
train_loss: 0.205, train_acc: 0.925
valid_loss: 0.330, valid_acc: 0.872
Saving ...
epoch: 5
train_loss: 0.153, train_acc: 0.947
valid_loss: 0.349, valid_acc: 0.876
test_loss: 0.362, test_acc: 0.872


hparam 32
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=290,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 16,509,126 trainable parameters
Saving ...
epoch: 1
train_loss: 0.504, train_acc: 0.753
valid_loss: 0.369, valid_acc: 0.842
Saving ...
epoch: 2
train_loss: 0.266, train_acc: 0.898
valid_loss: 0.296, valid_acc: 0.883
Saving ...
epoch: 3
train_loss: 0.186, train_acc: 0.933
valid_loss: 0.365, valid_acc: 0.874
Saving ...
epoch: 4
train_loss: 0.133, train_acc: 0.954
valid_loss: 0.359, valid_acc: 0.873
Saving ...
epoch: 5
train_loss: 0.098, train_acc: 0.969
valid_loss: 0.401, valid_acc: 0.870
test_loss: 0.419, test_acc: 0.866


hparam 33
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=305,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 3,722,800 trainable parameters
Saving ...
epoch: 1
train_loss: 0.686, train_acc: 0.567
valid_loss: 0.676, valid_acc: 0.590
Saving ...
epoch: 2
train_loss: 0.682, train_acc: 0.573
valid_loss: 0.678, valid_acc: 0.594
Saving ...
epoch: 3
train_loss: 0.579, train_acc: 0.684
valid_loss: 0.451, valid_acc: 0.788
Saving ...
epoch: 4
train_loss: 0.362, train_acc: 0.852
valid_loss: 0.361, valid_acc: 0.859
Saving ...
epoch: 5
train_loss: 0.244, train_acc: 0.909
valid_loss: 0.300, valid_acc: 0.874
test_loss: 0.317, test_acc: 0.869


hparam 34
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=305,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 12,762,844 trainable parameters
Saving ...
epoch: 1
train_loss: 0.575, train_acc: 0.679
valid_loss: 0.373, valid_acc: 0.845
Saving ...
epoch: 2
train_loss: 0.292, train_acc: 0.885
valid_loss: 0.317, valid_acc: 0.860
Saving ...
epoch: 3
train_loss: 0.182, train_acc: 0.934
valid_loss: 0.322, valid_acc: 0.871
Saving ...
epoch: 4
train_loss: 0.120, train_acc: 0.959
valid_loss: 0.349, valid_acc: 0.875
Saving ...
epoch: 5
train_loss: 0.084, train_acc: 0.974
valid_loss: 0.550, valid_acc: 0.877
test_loss: 0.590, test_acc: 0.869


hparam 35
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=305,LR=0.001,N_LAYERS=3,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 16,703,376 trainable parameters
Saving ...
epoch: 1
train_loss: 0.523, train_acc: 0.739
valid_loss: 0.378, valid_acc: 0.840
Saving ...
epoch: 2
train_loss: 0.280, train_acc: 0.890
valid_loss: 0.343, valid_acc: 0.859
Saving ...
epoch: 3
train_loss: 0.173, train_acc: 0.936
valid_loss: 0.356, valid_acc: 0.865
Saving ...
epoch: 4
train_loss: 0.122, train_acc: 0.959
valid_loss: 0.357, valid_acc: 0.858
Saving ...
epoch: 5
train_loss: 0.091, train_acc: 0.971
valid_loss: 0.439, valid_acc: 0.863
test_loss: 0.449, test_acc: 0.865


hparam 36
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=20,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 1,829,770 trainable parameters
Saving ...
epoch: 1
train_loss: 0.602, train_acc: 0.662
valid_loss: 0.431, valid_acc: 0.797
Saving ...
epoch: 2
train_loss: 0.323, train_acc: 0.869
valid_loss: 0.354, valid_acc: 0.855
Saving ...
epoch: 3
train_loss: 0.173, train_acc: 0.938
valid_loss: 0.322, valid_acc: 0.881
Saving ...
epoch: 4
train_loss: 0.091, train_acc: 0.971
valid_loss: 0.375, valid_acc: 0.882
Saving ...
epoch: 5
train_loss: 0.050, train_acc: 0.985
valid_loss: 0.520, valid_acc: 0.879
test_loss: 0.546, test_acc: 0.872


hparam 37
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=20,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 10,691,974 trainable parameters
Saving ...
epoch: 1
train_loss: 0.671, train_acc: 0.596
valid_loss: 0.639, valid_acc: 0.630
Saving ...
epoch: 2
train_loss: 0.477, train_acc: 0.777
valid_loss: 0.336, valid_acc: 0.863
Saving ...
epoch: 3
train_loss: 0.250, train_acc: 0.905
valid_loss: 0.305, valid_acc: 0.873
Saving ...
epoch: 4
train_loss: 0.129, train_acc: 0.958
valid_loss: 0.343, valid_acc: 0.875
Saving ...
epoch: 5
train_loss: 0.074, train_acc: 0.978
valid_loss: 0.394, valid_acc: 0.871
test_loss: 0.410, test_acc: 0.868


hparam 38
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=20,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 14,554,986 trainable parameters
Saving ...
epoch: 1
train_loss: 0.639, train_acc: 0.605
valid_loss: 0.447, valid_acc: 0.809
Saving ...
epoch: 2
train_loss: 0.331, train_acc: 0.866
valid_loss: 0.339, valid_acc: 0.860
Saving ...
epoch: 3
train_loss: 0.180, train_acc: 0.936
valid_loss: 0.338, valid_acc: 0.873
Saving ...
epoch: 4
train_loss: 0.098, train_acc: 0.968
valid_loss: 0.344, valid_acc: 0.882
Saving ...
epoch: 5
train_loss: 0.050, train_acc: 0.985
valid_loss: 0.461, valid_acc: 0.876
test_loss: 0.507, test_acc: 0.870


hparam 39
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=280,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 4,055,890 trainable parameters
Saving ...
epoch: 1
train_loss: 0.695, train_acc: 0.495
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 2
train_loss: 0.694, train_acc: 0.501
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 3
train_loss: 0.694, train_acc: 0.498
valid_loss: 0.693, valid_acc: 0.499
Saving ...
epoch: 4
train_loss: 0.693, train_acc: 0.493
valid_loss: 0.693, valid_acc: 0.499
Saving ...
epoch: 5
train_loss: 0.694, train_acc: 0.497
valid_loss: 0.694, valid_acc: 0.499
test_loss: 0.694, test_acc: 0.500


hparam 40
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=280,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 13,080,334 trainable parameters
Saving ...
epoch: 1
train_loss: 0.562, train_acc: 0.685
valid_loss: 0.354, valid_acc: 0.844
Saving ...
epoch: 2
train_loss: 0.288, train_acc: 0.888
valid_loss: 0.299, valid_acc: 0.877
Saving ...
epoch: 3
train_loss: 0.185, train_acc: 0.936
valid_loss: 0.295, valid_acc: 0.880
Saving ...
epoch: 4
train_loss: 0.119, train_acc: 0.961
valid_loss: 0.358, valid_acc: 0.881
Saving ...
epoch: 5
train_loss: 0.079, train_acc: 0.976
valid_loss: 0.428, valid_acc: 0.878
test_loss: 0.444, test_acc: 0.871


hparam 41
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=280,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 17,014,066 trainable parameters
Saving ...
epoch: 1
train_loss: 0.695, train_acc: 0.501
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 2
train_loss: 0.693, train_acc: 0.500
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 3
train_loss: 0.693, train_acc: 0.501
valid_loss: 0.694, valid_acc: 0.501
Saving ...
epoch: 4
train_loss: 0.694, train_acc: 0.497
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 5
train_loss: 0.694, train_acc: 0.500
valid_loss: 0.693, valid_acc: 0.501
test_loss: 0.693, test_acc: 0.500


hparam 42
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=290,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 4,217,110 trainable parameters
Saving ...
epoch: 1
train_loss: 0.695, train_acc: 0.499
valid_loss: 0.694, valid_acc: 0.501
Saving ...
epoch: 2
train_loss: 0.693, train_acc: 0.499
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 3
train_loss: 0.693, train_acc: 0.496
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 4
train_loss: 0.694, train_acc: 0.499
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 5
train_loss: 0.695, train_acc: 0.503
valid_loss: 0.694, valid_acc: 0.499
test_loss: 0.694, test_acc: 0.500


hparam 43
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=290,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 13,247,794 trainable parameters
Saving ...
epoch: 1
train_loss: 0.695, train_acc: 0.499
valid_loss: 0.693, valid_acc: 0.501
Saving ...
epoch: 2
train_loss: 0.694, train_acc: 0.494
valid_loss: 0.693, valid_acc: 0.499
Saving ...
epoch: 3
train_loss: 0.716, train_acc: 0.503
valid_loss: 0.696, valid_acc: 0.499
Saving ...
epoch: 4
train_loss: 0.705, train_acc: 0.497
valid_loss: 0.711, valid_acc: 0.504
Saving ...
epoch: 5
train_loss: 0.701, train_acc: 0.503
valid_loss: 0.697, valid_acc: 0.501
test_loss: 0.698, test_acc: 0.500


hparam 44
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=290,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 17,184,246 trainable parameters
Saving ...
epoch: 1
train_loss: 0.695, train_acc: 0.502
valid_loss: 0.693, valid_acc: 0.499
Saving ...
epoch: 2
train_loss: 0.693, train_acc: 0.499
valid_loss: 0.694, valid_acc: 0.499
Saving ...
epoch: 3
train_loss: 0.694, train_acc: 0.499
valid_loss: 0.693, valid_acc: 0.499
Saving ...
epoch: 4
train_loss: 0.694, train_acc: 0.497
valid_loss: 0.693, valid_acc: 0.499
Saving ...
epoch: 5
train_loss: 0.699, train_acc: 0.500
valid_loss: 0.694, valid_acc: 0.499
test_loss: 0.693, test_acc: 0.500


hparam 45
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=305,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 4,469,440 trainable parameters
Saving ...
epoch: 1
train_loss: 0.695, train_acc: 0.503
valid_loss: 0.694, valid_acc: 0.501
Saving ...
epoch: 2
train_loss: 0.694, train_acc: 0.501
valid_loss: 0.697, valid_acc: 0.501
Saving ...
epoch: 3
train_loss: 0.695, train_acc: 0.509
valid_loss: 0.693, valid_acc: 0.499
Saving ...
epoch: 4
train_loss: 0.693, train_acc: 0.510
valid_loss: 0.694, valid_acc: 0.501
Saving ...
epoch: 5
train_loss: 0.694, train_acc: 0.509
valid_loss: 0.693, valid_acc: 0.501
test_loss: 0.692, test_acc: 0.500


hparam 46
DROPOUT_RATE=0.2,EMBEDDING_DIM=188,HIDDEN_DIM=305,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 13,509,484 trainable parameters
Saving ...
epoch: 1
train_loss: 0.551, train_acc: 0.704
valid_loss: 0.424, valid_acc: 0.829
Saving ...
epoch: 2
train_loss: 0.316, train_acc: 0.874
valid_loss: 0.384, valid_acc: 0.853
Saving ...
epoch: 3
train_loss: 0.211, train_acc: 0.924
valid_loss: 0.340, valid_acc: 0.858
Saving ...
epoch: 4
train_loss: 0.165, train_acc: 0.944
valid_loss: 0.331, valid_acc: 0.872
Saving ...
epoch: 5
train_loss: 0.141, train_acc: 0.953
valid_loss: 0.443, valid_acc: 0.871
test_loss: 0.478, test_acc: 0.867


hparam 47
DROPOUT_RATE=0.2,EMBEDDING_DIM=256,HIDDEN_DIM=305,LR=0.001,N_LAYERS=4,OPTIM=rmsprop
shape of train data is 35000
shape of test data is 10000
shape of valid data is 5000
Length of vocabulary is 56729
The model has 17,450,016 trainable parameters
Saving ...
epoch: 1
train_loss: 0.697, train_acc: 0.524
valid_loss: 0.694, valid_acc: 0.534
Saving ...
epoch: 2
train_loss: 0.692, train_acc: 0.525
valid_loss: 0.692, valid_acc: 0.528
Saving ...
epoch: 3
train_loss: 0.692, train_acc: 0.529
valid_loss: 0.695, valid_acc: 0.537
Saving ...
epoch: 4
train_loss: 0.692, train_acc: 0.529
valid_loss: 0.691, valid_acc: 0.536
Saving ...
epoch: 5
train_loss: 0.692, train_acc: 0.530
valid_loss: 0.691, valid_acc: 0.535
test_loss: 0.689, test_acc: 0.544


max_test_acc 0.8801587496485029 ; which_hp 21
diff_hp for hp that reached max_test_acc 
DROPOUT_RATE=0.2,EMBEDDING_DIM=32,HIDDEN_DIM=305,LR=0.001,N_LAYERS=2,OPTIM=rmsprop
